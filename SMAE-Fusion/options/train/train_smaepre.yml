# General settings
name: ###
model_type: SMAEPreModel
num_gpu: 1  # set num_gpu: 0 for CPU mode
manual_seed: 42

# Dataset and data loader settings
datasets:
  train:
    name: LLVIP
    type: MSHATDataset
    is_train: True
    is_RGB: False
    dataroot_source1: ~
    dataroot_source2: ~
    mask_path: ~
    ir_map_path: ~
    vis_map_path: ~
    img_size: 128
    num_worker_per_gpu: 12
    batch_size_per_gpu: 8
    dataset_enlarge_ratio: 1
    pin_memory: true
    prefetch_mode: cuda

# Network structures
network_g:
  type: SMAEPretrain
  inp_channels: 1
  dim: 64
  img_size: 128
  mask_ratio: 0.75
  encoder_configs: {
      'num_blocks': 4,
      'dim': 64,
      'num_heads': 8,
      'ffn_expansion_factor': 4,
      'bias': False,
      'LayerNorm_type': 'WithBias',
      'reduction': 8,
      'kernel_size': 3,
  }
  decoder_configs: {
      'num_blocks': 2,
      'dim': 64,
      'num_heads': 4,
      'ffn_expansion_factor': 2,
      'bias': False,
      'LayerNorm_type': 'WithBias',
      'reduction': 8,
      'kernel_size': 3,
  }

# Training settings
train:
  ema_decay: 0  # EMA not used
  clip_grad: False
  # Optimizers
  optim_g:
    type: AdamW
    lr: !!float 4e-4
    weight_decay: !!float 1e-2
    betas: [0.9, 0.99]

  # Scheduler: Cosine Annealing with Restarts
  scheduler:
    type: CosineAnnealingRestartLR
    periods: [100000, 100000, 50000, 50000]
    restart_weights: [1, 1, 1, 1]
    eta_min: !!float 1e-5

  total_iter: 300000
  warmup_iter: 5000  # Warmup iterations
  # Loss function for pretraining
  mask_pixel_opt:
    type: MSELoss
    loss_weight: 1.0
    reduction: mean

###The remaining code is in progress and will be uploaded shortly###